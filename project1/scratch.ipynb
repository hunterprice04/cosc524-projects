{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lib import get_stop_words, get_text, get_lem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project gutenberg text has a lot of extra stuff at the beginning and end\n",
    "def get_text_no_gutenberg(raw_text):\n",
    "    return re.split('^\\*\\*\\*(.*)\\*\\*\\*$', raw_text, flags=re.MULTILINE)[2]\n",
    "    \n",
    "def remove_single_letter(text):\n",
    "    text = re.sub(r'\\b\\w\\b', ' ', text)\n",
    "    return text\n",
    "\n",
    "# split the raw text into chapters\n",
    "def split_chapters(text, roman_numeral=True):\n",
    "    if roman_numeral:\n",
    "        return re.split(r'CHAPTER [IVXLCDM]+', text, flags=re.IGNORECASE)\n",
    "    else:\n",
    "        return re.split(r'CHAPTER \\d+', text, flags=re.IGNORECASE)\n",
    "\n",
    "# sometimes the contents lists chapters that are in table of contents. here we just remove chapters that are too short.\n",
    "# here we also delete the first chapter, which is just the table of contents and preface\n",
    "def chapter_longer_than(raw_chapters, n=150):\n",
    "    return list(filter(lambda c: len(c) > n, raw_chapters))\n",
    "\n",
    "# split remove stopwords\n",
    "def remove_stopwords(text, stopwords):\n",
    "    return re.sub(r'\\b(' + '|'.join(stopwords) + r')\\b', '', text)\n",
    "\n",
    "# theres a ton of whitespace that we dont want\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def get_lem(fn):\n",
    "    text = []\n",
    "    lem = []\n",
    "    word = []\n",
    "    with open(fn, 'r', encoding='utf-8-sig') as f:\n",
    "        for i in f:\n",
    "            text.append([j for j in i.split()])\n",
    "    for i in range (len(text)):\n",
    "        lem.append(text[i][0])\n",
    "        word.append(text[i][1])\n",
    "    return text, lem, word\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    for i in range(len(text)):\n",
    "        text[i] = re.sub(r'[^\\w\\s]', lambda m: \".\" if m.group(0) == \".\" else \" \", text[i])\n",
    "    return text\n",
    "\n",
    "def split_sentence(text):\n",
    "    for i in range(len(text)):\n",
    "        text[i] = re.split(r\"[.]\", text[i])\n",
    "    return text\n",
    "\n",
    "def lemmatization (text, lem, word):\n",
    "    for i in range(len(text)):\n",
    "        text[i] = re.sub(r'\\b(' + '|'.join(word) + r')\\b', r'\\b(' + '|'.join(lem) + r')\\b', text[i])\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "books = [\n",
    "    {\n",
    "        'fn': 'a-study-in-scarlet.txt',\n",
    "        'roman_numeral': True\n",
    "    },\n",
    "    {\n",
    "        'fn': 'the-great-boer-war.txt',\n",
    "        'roman_numeral': False\n",
    "    },\n",
    "    {\n",
    "        'fn': 'the-hound-of-the-baskervilles.txt',\n",
    "        'roman_numeral': False\n",
    "    },\n",
    "    {\n",
    "        'fn':  'the-lost-world.txt',\n",
    "        'roman_numeral': True\n",
    "    },\n",
    "    {\n",
    "        'fn': 'the-sign-of-four.txt',\n",
    "        'roman_numeral': True\n",
    "    },\n",
    "]\n",
    "basedir = '../books/'\n",
    "stop_words = get_stop_words('stopwords.txt')\n",
    "text, lem, word = get_lem('lemmatization-en.txt')\n",
    "book_i = 1\n",
    "book_fn = books[book_i]['fn']\n",
    "book_rom_num = books[book_i]['roman_numeral']\n",
    "\n",
    "# get the raw text and make it all lower case\n",
    "raw_text = get_text(book_fn, basedir)\n",
    "raw_text = raw_text.lower()\n",
    "raw_text = get_text_no_gutenberg(raw_text)\n",
    "raw_text = remove_stopwords(raw_text, stop_words)\n",
    "raw_text = remove_extra_spaces(raw_text)\n",
    "\n",
    "raw_chapters = split_chapters(raw_text, book_rom_num)\n",
    "raw_chapters = chapter_longer_than(raw_chapters)[1:]\n",
    "raw_chapters = list(map(lambda c: remove_stopwords(c, stop_words), raw_chapters))\n",
    "raw_chapters = list(map(remove_extra_spaces, raw_chapters))\n",
    "raw_chapters  = remove_punctuation(raw_chapters)\n",
    "raw_chapters = split_sentence(raw_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_chapters[0]  = lemmatization (raw_chapters[0] , lem, word)\n",
    "print (raw_chapters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def porters_alg(text):\n",
    "    # https://vijinimallawaarachchi.com/2017/05/09/porter-stemming-algorithm/#:~:text=The%20Porter%20Stemming%20algorithm%20(or,of%20Information%20Retrieval%20(IR).\n",
    "    # https://tartarus.org/martin/PorterStemmer/\n",
    "    m = re.match(r'(\\w+?)(?=ly|es|(?<!s)s|y)', text)\n",
    "    print(m.groups())\n",
    "porters_alg('caresses days cates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_chapters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_chapters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(filter(lambda c: len(c) > 50, raw_chapters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.regex_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "textloc = \"books/a-study-in-scarlet.txt\"\n",
    "stopwordloc = 'project1\\stopwords.txt'\n",
    "text = GetTextFromFile(textloc)\n",
    "stopwords = GetStopWords(stopwordloc)\n",
    "clean_text = GetCleanText(text, stopwords)\n",
    "wordlist = GetUniqueWordList(clean_text)\n",
    "chapters = GetChapterTextList(text, stopwords)\n",
    "chapters_wordlist = GetChapterWordList(chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'w',encoding='utf-8') as f:\n",
    "    for w in nlp.Defaults.stop_words:\n",
    "        f.write(w + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b964ac9b30b36bbea2ffa1ada2bc35f19c0e363ef9f5256b2512afd4c34d440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
