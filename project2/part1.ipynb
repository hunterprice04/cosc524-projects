{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "# Project 2 - Part 1\n",
    "For the first part, use [the pretrained Bert model from hugging face](https://huggingface.co/transformers/task_summary.html#question-answering) and feed it with the five 300 words long sections from the book of your choice.\n",
    "These sections should be selected so they are: introducing the protagonist(s), the antagonist, the crime and crime scene, any significant evidence, and the resolution of the crime/a narrative that presents the case against the perpetrator.\n",
    "The questions you should ask are about the identity and characteristics of the protagonist, antagonist/perpetrator, the nature and the setting of the crime or crime scene, the evidence, and the case against the perpetrator.\n",
    "Document the questions, ask the questions and document the specificity and accuracy of the results.\n",
    "Then, feed the whole novel as a context, and repeat the questions. Document the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a6d31bfac64f43b35417e6eb6644c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Q_A (questions, text):\n",
    "    for question in questions:\n",
    "        inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "        input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        answer_start_scores = outputs.start_logits\n",
    "        answer_end_scores = outputs.end_logits\n",
    "\n",
    "    # Get the most likely beginning of answer with the argmax of the score\n",
    "        answer_start = tf.argmax(answer_start_scores, axis=1).numpy()[0]\n",
    "    # Get the most likely end of answer with the argmax of the score\n",
    "        answer_end = tf.argmax(answer_end_scores, axis=1).numpy()[0] + 1\n",
    "\n",
    "        answer = tokenizer.convert_tokens_to_string(\n",
    "            tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])\n",
    "        )\n",
    "\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    filename = os.path.join('text',text)\n",
    "    file = open(filename,encoding=\"utf8\")\n",
    "    word_list = file.readlines()\n",
    "    word_list = str(word_list).split()\n",
    "    for i in range(0, len(word_list), 300):\n",
    "        yield word_list[i:i + 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist?\n",
      "Answer: [CLS] who is the protagonist? [SEP]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS] who is the perpetrator? [SEP]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS] where was the first victim murdered? [SEP]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist?\",\n",
    "    \"Who is the perpetrator?\",\n",
    "    \"Where was the first victim murdered?\",\n",
    "]\n",
    "\n",
    "filename = os.path.join('text','antagonist.txt')\n",
    "file = open(filename,encoding=\"utf8\")\n",
    "text = file.read()\n",
    "Q_A (questions, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist?\n",
      "Answer: sir charles baskerville\n",
      "Question: Who is the perpetrator?\n",
      "Answer: sir charles baskerville\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: baskerville hall\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist?\",\n",
    "    \"Who is the perpetrator?\",\n",
    "    \"Where was the first victim murdered?\",\n",
    "]\n",
    "\n",
    "filename = os.path.join('text','crimescene.txt')\n",
    "file = open(filename,encoding=\"utf8\")\n",
    "text = file.read()\n",
    "Q_A (questions, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist?\n",
      "Answer: [CLS]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: \n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS] where was the first victim murdered? [SEP]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist?\",\n",
    "    \"Who is the perpetrator?\",\n",
    "    \"Where was the first victim murdered?\",\n",
    "]\n",
    "\n",
    "filename = os.path.join('text','evidence.txt')\n",
    "file = open(filename,encoding=\"utf8\")\n",
    "text = file.read()\n",
    "Q_A (questions, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist?\n",
      "Answer: mr. sherlock holmes\n",
      "Question: Who is the perpetrator?\n",
      "Answer: \n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS] where was the first victim murdered? [SEP]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist?\",\n",
    "    \"Who is the perpetrator?\",\n",
    "    \"Where was the first victim murdered?\",\n",
    "]\n",
    "\n",
    "filename = os.path.join('text','protaganists.txt')\n",
    "file = open(filename,encoding=\"utf8\")\n",
    "text = file.read()\n",
    "Q_A (questions, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist?\n",
      "Answer: [CLS] who is the protagonist? [SEP]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS] who is the perpetrator? [SEP]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS] where was the first victim murdered? [SEP]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist?\",\n",
    "    \"Who is the perpetrator?\",\n",
    "    \"Where was the first victim murdered?\",\n",
    "]\n",
    "\n",
    "filename = os.path.join('text','resolution.txt')\n",
    "file = open(filename,encoding=\"utf8\")\n",
    "text = file.read()\n",
    "Q_A (questions, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist?\n",
      "Answer: [CLS]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS]\n",
      "Question: Who is the protagonist?\n",
      "Answer: [CLS]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS]\n",
      "Question: Who is the protagonist?\n",
      "Answer: [CLS]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS]\n",
      "Question: Who is the protagonist?\n",
      "Answer: [CLS]\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS]\n",
      "Question: Who is the protagonist?\n",
      "Answer: hugo baskerville\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS]\n",
      "Question: Who is the protagonist?\n",
      "Answer: [CLS] who is the protagonist? [SEP] thing great black beast shape like hound large hound mortal eye rest. look thing tear throat hugo baskerville\n",
      "Question: Who is the perpetrator?\n",
      "Answer: [CLS]\n",
      "Question: Where was the first victim murdered?\n",
      "Answer: [CLS]\n",
      "Question: Who is the protagonist?\n",
      "Answer: [CLS]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zimin\\Documents\\GitHub\\cosc524-projects\\project2\\part1.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(word_list)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(item) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m word_list[i]])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     Q_A (questions, text)\n",
      "\u001b[1;32mc:\\Users\\zimin\\Documents\\GitHub\\cosc524-projects\\project2\\part1.ipynb Cell 13\u001b[0m in \u001b[0;36mQ_A\u001b[1;34m(questions, text)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(question, text, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m input_ids \u001b[39m=\u001b[39m inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m answer_start_scores \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mstart_logits\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zimin/Documents/GitHub/cosc524-projects/project2/part1.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m answer_end_scores \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mend_logits\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py:412\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    411\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 412\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1991\u001b[0m, in \u001b[0;36mTFBertForQuestionAnswering.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, start_positions, end_positions, training)\u001b[0m\n\u001b[0;32m   1956\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[0;32m   1957\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1958\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1979\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1980\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFQuestionAnsweringModelOutput, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[0;32m   1981\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1982\u001b[0m \u001b[39m    start_positions (`tf.Tensor` or `np.ndarray` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1983\u001b[0m \u001b[39m        Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1989\u001b[0m \u001b[39m        are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1991\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1992\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1993\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1994\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1995\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1996\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1997\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1998\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1999\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   2000\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   2001\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m   2002\u001b[0m     )\n\u001b[0;32m   2003\u001b[0m     sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2004\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqa_outputs(inputs\u001b[39m=\u001b[39msequence_output)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py:412\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    411\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 412\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:873\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[1;32m--> 873\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    874\u001b[0m     hidden_states\u001b[39m=\u001b[39;49membedding_output,\n\u001b[0;32m    875\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    876\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    877\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    878\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    879\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    880\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    881\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    882\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    883\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    884\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    885\u001b[0m )\n\u001b[0;32m    887\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    888\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(hidden_states\u001b[39m=\u001b[39msequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:564\u001b[0m, in \u001b[0;36mTFBertEncoder.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    560\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m    562\u001b[0m past_key_value \u001b[39m=\u001b[39m past_key_values[i] \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    565\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    566\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    568\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    569\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    570\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    571\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    572\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    573\u001b[0m )\n\u001b[0;32m    574\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    576\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:521\u001b[0m, in \u001b[0;36mTFBertLayer.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[0;32m    518\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m    520\u001b[0m intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(hidden_states\u001b[39m=\u001b[39mattention_output)\n\u001b[1;32m--> 521\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert_output(\n\u001b[0;32m    522\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mintermediate_output, input_tensor\u001b[39m=\u001b[39;49mattention_output, training\u001b[39m=\u001b[39;49mtraining\n\u001b[0;32m    523\u001b[0m )\n\u001b[0;32m    524\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:442\u001b[0m, in \u001b[0;36mTFBertOutput.call\u001b[1;34m(self, hidden_states, input_tensor, training)\u001b[0m\n\u001b[0;32m    440\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(inputs\u001b[39m=\u001b[39mhidden_states)\n\u001b[0;32m    441\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(inputs\u001b[39m=\u001b[39mhidden_states, training\u001b[39m=\u001b[39mtraining)\n\u001b[1;32m--> 442\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(inputs\u001b[39m=\u001b[39mhidden_states \u001b[39m+\u001b[39;49m input_tensor)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1407\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1403\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1407\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1408\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1409\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1757\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1755\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39madd(x, y, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   1756\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49madd_v2(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\zimin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:461\u001b[0m, in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    460\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    462\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mAddV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[0;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    464\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist?\",\n",
    "    \"Who is the perpetrator?\",\n",
    "    \"Where was the first victim murdered?\",\n",
    "]\n",
    "word_list = list(split_text('the-hound-of-the-baskervilles.txt'))\n",
    "\n",
    "for i in range(len(word_list)):\n",
    "    text = ' '.join([str(item) for item in word_list[i]])\n",
    "\n",
    "    Q_A (questions, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b964ac9b30b36bbea2ffa1ada2bc35f19c0e363ef9f5256b2512afd4c34d440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
